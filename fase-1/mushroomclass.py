# -*- coding: utf-8 -*-
"""MushroomClass.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eub_o3Kc3RyL0myHS6Afckse6i7yK8hx

Instalamos todas las librerías necesarias para el proyecto de machine learning.
"""

! pip install kaggle
! pip install dython
! pip install category_encoders
! pip install lime
! pip install plotly
! pip install xgboost
! pip install lightgbm

"""Configuramos las credenciales de Kaggle y descargamos el dataset necesario para el proyecto."""

import json
data = {"username":"danielyepesmesa","key":"84aa2288a3d961af65fb22e9ccda4433"}
with open('kaggle.json', 'w') as file:
    json.dump(data, file, indent=4)
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle competitions download -c playground-series-s4e8
! unzip playground-series-s4e8.zip

"""Importamos las librerías y módulos necesarios para el análisis, visualización y modelado de datos."""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder,OrdinalEncoder
from xgboost import XGBRegressor
import lightgbm as lgb
import gc
import seaborn as sns
import category_encoders as ce
import plotly.express as px
from dython.nominal import associations
from sklearn.impute import KNNImputer
import plotly.graph_objects as go
import lime
import lime.lime_tabular
from sklearn.metrics import matthews_corrcoef
from xgboost import XGBClassifier

"""Cargamos los datos de entrenamiento, prueba y la muestra de envío desde archivos CSV."""

df_sub=pd.read_csv("sample_submission.csv")
df_train=pd.read_csv("train.csv")
df_test=pd.read_csv("test.csv")

"""Mostramos las primeras filas del DataFrame de entrenamiento para visualizar la estructura y el contenido de los datos.







"""

df_train.head()

"""Mostramos las primeras filas del DataFrame de prueba para revisar la estructura y el contenido de los datos de test."""

df_test.head()

"""Verificamos las dimensiones de los DataFrames de prueba y entrenamiento para entender el tamaño de los conjuntos de datos."""

df_test.shape,df_train.shape

"""Eliminamos la columna 'id' de los DataFrames de entrenamiento y prueba, ya que no es relevante para el análisis."""

df_train = df_train.drop(columns=['id'])
df_test = df_test.drop(columns=['id'])

"""Obtenemos un resumen de la información del DataFrame de entrenamiento, incluyendo el tipo de datos y los valores nulos."""

df_train.info()

"""Identificamos las columnas categóricas en el DataFrame de entrenamiento, contamos el número de valores únicos en cada una y mostramos esa información. Finalmente, liberamos memoria innecesaria utilizando la recolección de basura (garbage collection)."""

categorical_columns = df_train.select_dtypes(include=['object']).columns
unique_values = {col: df_train[col].nunique() for col in categorical_columns}
for col, unique_count in unique_values.items():
    print(f"{col}: {unique_count} unique values")

gc.collect()

"""Identificamos las columnas categóricas en el DataFrame de prueba, contamos el número de valores únicos en cada una y mostramos esa información. Luego, liberamos memoria innecesaria utilizando la recolección de basura (garbage collection)."""

categorical_columns = df_test.select_dtypes(include=['object']).columns
unique_values = {col: df_test[col].nunique() for col in categorical_columns}
for col, unique_count in unique_values.items():
    print(f"{col}: {unique_count} unique values")

gc.collect()

"""Mostramos los nombres de las columnas presentes en el DataFrame de prueba."""

df_test.columns

"""Mostramos los nombres de las columnas presentes en el DataFrame de entrenamiento."""

df_train.columns

"""Calculamos el porcentaje de valores faltantes en cada columna de los DataFrames de entrenamiento y prueba, y mostramos las columnas que tienen más del 10% de valores faltantes."""

missing_train = df_train.isna().mean() * 100
missing_test = df_test.isna().mean() * 100

print("Columns in df_train with more than 10% missing values:")
print(missing_train[missing_train > 0])

print("\nColumns in df_test with more than 10% missing values:")
print(missing_test[missing_test > 0])

"""Identificamos y ordenamos las columnas del DataFrame de entrenamiento con valores faltantes, luego visualizamos la distribución de estos valores faltantes mediante un gráfico de barras."""

missing_values = df_train.isnull().mean() * 100
missing_values = missing_values[missing_values >0]
missing_values = missing_values.sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=missing_values.index, y=missing_values.values, palette='viridis')
plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Percentage of Missing Values')
plt.title('Missing Values Distribution in df_train')
plt.show()

"""Eliminamos las columnas del DataFrame de entrenamiento y prueba que tienen más del 95% de valores faltantes. Luego, para las columnas que aún tienen valores faltantes, rellenamos los valores nulos: en las columnas categóricas, con la moda, y en las numéricas, con la mediana."""

missing_threshold = 0.95

high_missing_columns = df_train.columns[df_train.isnull().mean() > missing_threshold]

df_train = df_train.drop(columns=high_missing_columns)
df_test = df_test.drop(columns=high_missing_columns)
target = 'class'

for column in df_train.columns:
    if df_train[column].isnull().any():
        if df_train[column].dtype == 'object':
            mode_value = df_train[column].mode()[0]
            df_train[column].fillna(mode_value, inplace=True)
            df_test[column].fillna(mode_value, inplace=True)
        else:
            median_value = df_train[column].median()
            df_train[column].fillna(median_value, inplace=True)
            df_test[column].fillna(median_value, inplace=True)

"""Calculamos la matriz de correlación, incluyendo variables categóricas, para una muestra del DataFrame de entrenamiento. Luego, visualizamos esta matriz de correlación utilizando un mapa de calor.

"""

associations_df = associations(df_train[:10000], nominal_columns='all', plot=False)
corr_matrix = associations_df['corr']
plt.figure(figsize=(20, 8))
plt.gcf().set_facecolor('#FFFDD0')
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix including Categorical Features')
plt.show()

"""Creamos una copia de una muestra del DataFrame de entrenamiento y generamos un gráfico de sunburst para visualizar la distribución conjunta de las características 'cap-shape' y 'cap-color'."""

df_train1 = df_train[:10000].copy()

feature_counts = df_train1.groupby(['cap-shape', 'cap-color']).size().reset_index(name='count')
fig = px.sunburst(feature_counts, path=['cap-shape', 'cap-color'], values='count',
                 color='count', color_continuous_scale='Viridis',
                 title='Sunburst Chart of Cap Shape and Cap Color Distribution')

fig.update_layout(title_text='Sunburst Chart of Cap Shape and Cap Color Distribution',
                  title_x=0.5,width=900,height=600)
fig.show()

"""Creamos un gráfico de Sankey para visualizar el flujo y la relación entre las características 'cap-shape' y 'cap-color' en la muestra del DataFrame de entrenamiento."""

flow_data = df_train1.groupby(['cap-shape', 'cap-color']).size().reset_index(name='count')
labels = list(pd.concat([flow_data['cap-shape'], flow_data['cap-color']]).unique())
label_map = {label: idx for idx, label in enumerate(labels)}

sources = flow_data['cap-shape'].map(label_map).tolist()
targets = flow_data['cap-color'].map(label_map).tolist()
values = flow_data['count'].tolist()


fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color='black', width=0.5),
        label=labels
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values
    )
)])

fig.update_layout(
    title_text='Sankey Chart of Cap Shape to Cap Color Flow',
    title_x=0.5,
    width=1000,
    height=600
)
fig.show()

"""Generamos un gráfico de barras apiladas para mostrar la relación y distribución conjunta entre las características 'cap-shape' y 'cap-color', utilizando los datos de la muestra del DataFrame de entrenamiento.

"""

feature_counts = df_train1.groupby(['cap-shape', 'cap-color']).size().reset_index(name='count')
fig = px.bar(feature_counts, x='cap-shape', y='count', color='cap-color',
             title='Crosstab Chart of Cap Shape and Cap Color',
             labels={'cap-shape': 'Cap Shape', 'count': 'Count', 'cap-color': 'Cap Color'},
             color_discrete_sequence=px.colors.qualitative.Plotly,
             text='count')
fig.update_layout(
    title_text='Crosstab Chart of Cap Shape and Cap Color',
    title_x=0.5,
    xaxis_title='Cap Shape',
    yaxis_title='Count',
    barmode='stack'
)

fig.show()

"""Eliminamos las columnas de los DataFrames de entrenamiento y prueba que tienen más del 95% de valores faltantes, y luego liberamos memoria utilizando la recolección de basura (garbage collection).

"""

cols_to_drop_train = missing_train[missing_train > 95].index
cols_to_drop_test = missing_test[missing_test > 95].index

df_train = df_train.drop(columns=cols_to_drop_train)
df_test = df_test.drop(columns=cols_to_drop_test)
gc.collect()

"""Definimos una función para imputar valores faltantes en un DataFrame utilizando KNN (K-Nearest Neighbors). Primero, codificamos las columnas categóricas como números, luego aplicamos KNNImputer, y finalmente, decodificamos las columnas categóricas a sus valores originales."""

def knn_impute(df, n_neighbors=5):
    df_encoded = df.copy()
    for col in df_encoded.select_dtypes(include='object').columns:
        df_encoded[col] = df_encoded[col].astype('category').cat.codes
    knn_imputer = KNNImputer(n_neighbors=n_neighbors)
    df_imputed = pd.DataFrame(knn_imputer.fit_transform(df_encoded), columns=df_encoded.columns)
    for col in df.select_dtypes(include='object').columns:
        df_imputed[col] = df_imputed[col].round().astype(int).map(
            dict(enumerate(df[col].astype('category').cat.categories)))
    return df_imputed

"""Aplicamos la función de imputación KNN a los DataFrames de entrenamiento y prueba, rellenando los valores faltantes con base en los vecinos más cercanos."""

df_train_imputed = knn_impute(df_train, n_neighbors=5)
df_test_imputed = knn_impute(df_test, n_neighbors=5)

"""Identificamos las columnas categóricas en los DataFrames de entrenamiento y prueba (excluyendo la columna objetivo 'class') y las transformamos en valores ordinales utilizando un codificador ordinal. Esto facilita su uso en modelos de machine learning."""

cat_cols_train = df_train_imputed.select_dtypes(include=['object']).columns
cat_cols_train = cat_cols_train[cat_cols_train != 'class']
ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)

df_train_imputed[cat_cols_train] = ordinal_encoder.fit_transform(df_train_imputed[cat_cols_train].astype(str))
df_test_imputed[cat_cols_train] = ordinal_encoder.transform(df_test_imputed[cat_cols_train].astype(str))

"""Mostramos las primeras filas del DataFrame de entrenamiento imputado para revisar el resultado de las transformaciones y la imputación de valores faltantes."""

df_train_imputed.head()

"""Mostramos las primeras filas del DataFrame de prueba imputado para verificar las transformaciones y la imputación de valores faltantes.

"""

df_test_imputed.head()

"""Asignamos los DataFrames imputados y transformados de vuelta a las variables originales de entrenamiento y prueba para su uso en los siguientes pasos del análisis.

"""

df_train = df_train_imputed
df_test = df_test_imputed

"""Mostramos las primeras filas del DataFrame de prueba actualizado para verificar que los datos imputados y transformados estén correctamente asignados."""

df_test.head()

"""Codificamos la variable objetivo 'class' en el DataFrame de entrenamiento utilizando LabelEncoder, transformando las etiquetas categóricas en valores numéricos.

"""

le = LabelEncoder()
df_train['class'] = le.fit_transform(df_train['class'])

"""Separamos la variable objetivo 'class' (y) del resto de las características (X) en el DataFrame de entrenamiento para prepararlas para el modelado.

"""

y = df_train['class']
X = df_train.drop(['class'],axis=1)

"""Dividimos los datos en conjuntos de entrenamiento y prueba, manteniendo la proporción original de la variable objetivo 'class' mediante estratificación. Usamos un 20% de los datos para el conjunto de prueba."""

train_X, test_X, train_y, test_y = train_test_split(X, y,test_size = 0.2, random_state =42,stratify=y)

"""Definimos una función para calcular el coeficiente de correlación de Matthews (MCC), que es una métrica utilizada para evaluar la calidad de las predicciones binarias. La función convierte las predicciones en valores binarios y calcula el MCC comparándolo con las etiquetas verdaderas."""

def mcc_metric(y_pred, dmatrix):
    y_true = dmatrix.get_label()
    y_pred = (y_pred > 0.5).astype(int)
    mcc = matthews_corrcoef(y_true, y_pred)
    return 'mcc', mcc

"""Entrenamos un modelo de clasificación XGBoost con un conjunto específico de hiperparámetros utilizando los datos de entrenamiento. Además, evaluamos el modelo en el conjunto de prueba durante el proceso de entrenamiento.

"""

model = XGBClassifier(
    alpha=0.1,
    subsample=0.8,
    colsample_bytree=0.6,
    objective='binary:logistic',
    max_depth=14,
    min_child_weight=7,
    gamma=1e-6,
    #random_state=42,
    n_estimators=100
    )

XGB = model.fit(
    train_X,
    train_y,
    eval_set=[(test_X, test_y)])

"""Generamos predicciones con el modelo XGBoost entrenado utilizando los datos del conjunto de prueba."""

y_pred = XGB.predict(test_X)

"""Generamos predicciones con el modelo XGBoost entrenado utilizando los datos del conjunto de prueba."""

redict_fn_xgb = lambda x: XGB.predict_proba(x).astype(float)
X = train_X.values
explainer = lime.lime_tabular.LimeTabularExplainer(X,feature_names = train_X.columns,class_names=['Poisnous','edible'],kernel_width=5)

"""Mostramos las primeras cuatro filas del DataFrame de prueba para revisar una muestra de los datos después de las transformaciones y antes de realizar predicciones."""

df_test.head(4)

"""Mostramos la fila correspondiente al índice 3 del DataFrame de prueba para inspeccionar en detalle una instancia específica de los datos."""

df_test.loc[[3]]

"""Mostramos el conjunto de características `test_X`, que contiene las variables predictoras del conjunto de prueba, preparadas para realizar predicciones con el modelo."""

test_X

"""Seleccionamos una instancia específica del conjunto de prueba para explicar su predicción usando la librería LIME, la cual destaca las 15 características más importantes que influyen en la predicción del modelo XGBoost.

"""

choosen_instance = test_X.loc[[1584520]].values[0]
exp = explainer.explain_instance(choosen_instance, redict_fn_xgb,num_features=15)
exp.show_in_notebook(show_all=False)

"""Seleccionamos otra instancia específica del conjunto de prueba para explicar su predicción utilizando LIME, mostrando las 15 características más influyentes en la decisión del modelo XGBoost.

"""

choosen_instance = test_X.loc[[2244255]].values[0]
exp = explainer.explain_instance(choosen_instance, redict_fn_xgb,num_features=15)
exp.show_in_notebook(show_all=False)

"""Seleccionamos una nueva instancia específica del conjunto de prueba para explicar su predicción con LIME, visualizando las 15 características más importantes para el modelo XGBoost en esta predicción.

"""

choosen_instance = test_X.loc[[421615]].values[0]
exp = explainer.explain_instance(choosen_instance, redict_fn_xgb,num_features=15)
exp.show_in_notebook(show_all=False)

"""Seleccionamos una instancia adicional del conjunto de prueba para explicar su predicción con LIME, destacando las 15 características que más influyen en la predicción del modelo XGBoost.

"""

choosen_instance = test_X.loc[[2921070]].values[0]
exp = explainer.explain_instance(choosen_instance, redict_fn_xgb,num_features=15)
exp.show_in_notebook(show_all=False)

"""Seleccionamos otra instancia específica del conjunto de prueba para explicar su predicción utilizando LIME, resaltando las 15 características más influyentes en la predicción del modelo XGBoost.

"""

choosen_instance = test_X.loc[[44159]].values[0]
exp = explainer.explain_instance(choosen_instance, redict_fn_xgb,num_features=15)
exp.show_in_notebook(show_all=False)

"""Calculamos y mostramos el coeficiente de correlación de Matthews (MCC) para evaluar la calidad de las predicciones del modelo en el conjunto de prueba.

"""

score = matthews_corrcoef(test_y, y_pred)
print('MCC:', score)

"""Generamos predicciones con el modelo XGBoost entrenado utilizando el DataFrame de prueba completo."""

test_pred_prob = XGB.predict(df_test)

"""Mostramos las predicciones generadas por el modelo XGBoost para el DataFrame de prueba."""

test_pred_prob

"""Convertimos las predicciones numéricas en sus clases originales utilizando `LabelEncoder` para revertir la codificación, obteniendo así las clases categóricas predichas."""

test_pred_class = le.inverse_transform(test_pred_prob)

"""Asignamos las clases predichas al DataFrame de envío (`df_sub`), asociando las predicciones con la columna 'class'.

"""

df_sub['class']= test_pred_class

"""Guardamos el DataFrame de envío con las predicciones en un archivo CSV llamado 'submission.csv' y luego lo leemos para verificar que se haya guardado correctamente.

"""

df_sub.to_csv('submission.csv', index = False)
pd.read_csv('submission.csv')

"""Generamos un histograma para visualizar la distribución de las clases predichas en el DataFrame de envío.

"""

df_sub['class'].hist()